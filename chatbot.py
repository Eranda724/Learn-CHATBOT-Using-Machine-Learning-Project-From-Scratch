# -*- coding: utf-8 -*-
"""chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MsZNXIscUT9G8OT2HcgqMD4u6nfMCNR_
"""

import numpy as np
import json #conversation dataset
import tensorflow as tf

from tensorflow import keras
from tensorflow.keras.models import Sequential #convert inter in fixed size
from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D #get avg values of training
from tensorflow.keras.preprocessing.text import Tokenizer #extract features
from tensorflow.keras.preprocessing.sequence import pad_sequences #pad sequences convert sequence of word into 0-9, 0-10, 0-11
from sklearn.preprocessing import LabelEncoder #converts words to numerical format

#IMPORT DATASET
with open('intents.json') as file:
    data = json.load(file)


training_sentences = []
training_labels = []
labels = []
responses = []

for intent in data['intents']:
  for pattern in intent['patterns']:
    training_sentences.append(pattern)
    training_labels.append(intent['tag'])
  responses.append(intent['responses'])

  if intent['tag'] not in labels:
    labels.append(intent['tag'])

num_classes = len(labels)

LabelEncoder = LabelEncoder()
LabelEncoder.fit(training_labels)
training_labels = LabelEncoder.transform(training_labels) #0 and 1

#tokenisation understand machine lang
vocab_size = 1000
embedding_dim = 16
max_len = 20 #input size
oov_token = "<OOV>" #out of vocabulry

tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_token)
tokenizer.fit_on_texts(training_sentences)
word_index = tokenizer.word_index

sequences = tokenizer.texts_to_sequences(training_sentences)
padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_len)

#training neural network
model= Sequential()

model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))

model.add(GlobalAveragePooling1D())

model.add(Dense(16, activation='relu'))
model.add(Dense(num_classes, activation='softmax')) #define the classes

model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()
epochs = 100
history = model.fit(padded_sequences, np.array(training_labels), epochs=epochs)

#save the model
model.save("chat.keras")

import pickle #save the model

with open('tokenizer.pickle', 'wb') as handle:
  pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('label_encoder.pickle', 'wb') as ecn_file:
  pickle.dump(LabelEncoder, ecn_file, protocol=pickle.HIGHEST_PROTOCOL)

#create conversattion
#!pip install colorama
import colorama
colorama.init()
from colorama import Fore, Style, Back #front , style , back
import random #random conversations

import random

with open('intents.json') as file:
  data = json.load(file)

def chat():
  model= keras.models.load_model('chat.keras')

  with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

  with open('label_encoder.pickle', 'rb') as enc:
    LabelEncoder = pickle.load(enc)

    max_len = 20

  while True:
    print(Fore.LIGHTBLUE_EX + "User: " + Style.RESET_ALL, end="")
    inp = input()
    if inp.lower() == "quit":
      break

    result = model.predict(keras.preprocessing.sequence.pad_sequences(
        tokenizer.texts_to_sequences([inp]),truncating='post', maxlen=max_len))

    tag = LabelEncoder.inverse_transform([np.argmax(result)])

    for i in data['intents']:
      if i['tag'] == tag:
        print(Fore.GREEN + "ChatBot:" + Style.RESET_ALL , np.random.choice(i['responses'])) #3 responses
        break
      
print(Fore.YELLOW + "Start messaging with the bot (type quit to stop)!" + Style.RESET_ALL)
chat()